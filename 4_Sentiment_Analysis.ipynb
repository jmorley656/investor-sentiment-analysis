{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (textacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textacy Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T12:58:32.318474Z",
     "start_time": "2022-03-31T12:58:31.985998Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as notebook\n",
    "import textacy\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GGP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T11:38:05.043815Z",
     "start_time": "2022-03-30T11:38:03.790798Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../GA/Capstone/scrapes/large_scrape_29-Mar-22_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T11:38:05.795956Z",
     "start_time": "2022-03-30T11:38:05.773257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>opinion</th>\n",
       "      <th>price</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>hydrogen</td>\n",
       "      <td>RE: Hydro</td>\n",
       "      <td>Yes Sir.</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>yes sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>Sycho</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Lets keep your 12:35 post to ourselves and kee...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>lets keep your post ourselves and keep realyou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>TomE</td>\n",
       "      <td>GGPSP</td>\n",
       "      <td>So what happened to the \"Expect a sudden jump ...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>what happened the expect sudden jump price its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>Sycho</td>\n",
       "      <td>RE: Personally in my opinion</td>\n",
       "      <td>LOL, now that's more like it.</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>lol now thats more like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>Shady69</td>\n",
       "      <td>RE: Personally in my opinion</td>\n",
       "      <td>Hydro it's so well put it could bring a tear t...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>hydro its well put could bring tear glass eye ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      user                         title  \\\n",
       "0  7 Dec '21  hydrogen                     RE: Hydro   \n",
       "1  7 Dec '21     Sycho                         Hydro   \n",
       "2  7 Dec '21      TomE                         GGPSP   \n",
       "3  7 Dec '21     Sycho  RE: Personally in my opinion   \n",
       "4  7 Dec '21   Shady69  RE: Personally in my opinion   \n",
       "\n",
       "                                             comment     opinion  price  \\\n",
       "0                                           Yes Sir.  No Opinion  14.05   \n",
       "1  Lets keep your 12:35 post to ourselves and kee...  No Opinion  14.05   \n",
       "2  So what happened to the \"Expect a sudden jump ...  No Opinion  14.05   \n",
       "3                      LOL, now that's more like it.  No Opinion  14.05   \n",
       "4  Hydro it's so well put it could bring a tear t...  No Opinion  14.05   \n",
       "\n",
       "                                       comment_clean  \n",
       "0                                            yes sir  \n",
       "1  lets keep your post ourselves and keep realyou...  \n",
       "2  what happened the expect sudden jump price its...  \n",
       "3                            lol now thats more like  \n",
       "4  hydro its well put could bring tear glass eye ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T11:38:51.560190Z",
     "start_time": "2022-03-30T11:38:51.460543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>opinion</th>\n",
       "      <th>price</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>5 Dec '21</td>\n",
       "      <td>mickey1122</td>\n",
       "      <td>RE: WOH !</td>\n",
       "      <td>https://twitter.com/trader****ney/status/14676...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5 Dec '21</td>\n",
       "      <td>mickey1122</td>\n",
       "      <td>WOH !</td>\n",
       "      <td>https://twitter.com/trader****ney/status/14676...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4 Dec '21</td>\n",
       "      <td>TallChapJG</td>\n",
       "      <td>Gold shortage</td>\n",
       "      <td>https://kingworldnews.com/alert-we-are-now-see...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>3 Dec '21</td>\n",
       "      <td>Bamps21</td>\n",
       "      <td>RE: AMEC AWARDS</td>\n",
       "      <td>https://twitter.com/kristiebatten/status/14663...</td>\n",
       "      <td>Strong Buy</td>\n",
       "      <td>14.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>3 Dec '21</td>\n",
       "      <td>TimberTrader</td>\n",
       "      <td>RE: Greatland Gold plc 38.5% potential upside ...</td>\n",
       "      <td>https://www.***************************/greatl...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132348</th>\n",
       "      <td>27 Jan '22</td>\n",
       "      <td>Bamps21</td>\n",
       "      <td>Drill results</td>\n",
       "      <td>https://www.google.co.uk/search?q=jan+22+newcr...</td>\n",
       "      <td>Strong Buy</td>\n",
       "      <td>13.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132388</th>\n",
       "      <td>27 Jan '22</td>\n",
       "      <td>spoon_key</td>\n",
       "      <td>:)</td>\n",
       "      <td>https://www.youtube.com/watch?v=z5OXON8vIaA</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>13.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132508</th>\n",
       "      <td>27 Jan '22</td>\n",
       "      <td>geejay13</td>\n",
       "      <td>RE: Live price please as stuck at work</td>\n",
       "      <td>13,68</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>13.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132549</th>\n",
       "      <td>27 Jan '22</td>\n",
       "      <td>Hopefullygold</td>\n",
       "      <td>RE: Pivot point</td>\n",
       "      <td>https://globalarbitrationreview.com/guide/the-...</td>\n",
       "      <td>Strong Buy</td>\n",
       "      <td>13.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132552</th>\n",
       "      <td>26 Jan '22</td>\n",
       "      <td>Montyfino</td>\n",
       "      <td>RE: NC Quarterly</td>\n",
       "      <td>https://m.miningweekly.com/article/newcrest-wi...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>13.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2019 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date           user  \\\n",
       "219      5 Dec '21     mickey1122   \n",
       "220      5 Dec '21     mickey1122   \n",
       "312      4 Dec '21     TallChapJG   \n",
       "360      3 Dec '21        Bamps21   \n",
       "375      3 Dec '21   TimberTrader   \n",
       "...            ...            ...   \n",
       "132348  27 Jan '22        Bamps21   \n",
       "132388  27 Jan '22      spoon_key   \n",
       "132508  27 Jan '22       geejay13   \n",
       "132549  27 Jan '22  Hopefullygold   \n",
       "132552  26 Jan '22      Montyfino   \n",
       "\n",
       "                                                    title  \\\n",
       "219                                             RE: WOH !   \n",
       "220                                                 WOH !   \n",
       "312                                         Gold shortage   \n",
       "360                                       RE: AMEC AWARDS   \n",
       "375     RE: Greatland Gold plc 38.5% potential upside ...   \n",
       "...                                                   ...   \n",
       "132348                                      Drill results   \n",
       "132388                                                 :)   \n",
       "132508             RE: Live price please as stuck at work   \n",
       "132549                                    RE: Pivot point   \n",
       "132552                                   RE: NC Quarterly   \n",
       "\n",
       "                                                  comment     opinion  price  \\\n",
       "219     https://twitter.com/trader****ney/status/14676...  No Opinion  14.15   \n",
       "220     https://twitter.com/trader****ney/status/14676...  No Opinion  14.15   \n",
       "312     https://kingworldnews.com/alert-we-are-now-see...  No Opinion  14.15   \n",
       "360     https://twitter.com/kristiebatten/status/14663...  Strong Buy  14.50   \n",
       "375     https://www.***************************/greatl...  No Opinion  14.60   \n",
       "...                                                   ...         ...    ...   \n",
       "132348  https://www.google.co.uk/search?q=jan+22+newcr...  Strong Buy  13.70   \n",
       "132388        https://www.youtube.com/watch?v=z5OXON8vIaA  No Opinion  13.70   \n",
       "132508                                              13,68  No Opinion  13.80   \n",
       "132549  https://globalarbitrationreview.com/guide/the-...  Strong Buy  13.90   \n",
       "132552  https://m.miningweekly.com/article/newcrest-wi...  No Opinion  13.90   \n",
       "\n",
       "       comment_clean  \n",
       "219              NaN  \n",
       "220              NaN  \n",
       "312              NaN  \n",
       "360              NaN  \n",
       "375              NaN  \n",
       "...              ...  \n",
       "132348           NaN  \n",
       "132388           NaN  \n",
       "132508           NaN  \n",
       "132549           NaN  \n",
       "132552           NaN  \n",
       "\n",
       "[2019 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any null rows\n",
    "df[df.isnull().sum(axis=1)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T11:40:54.056237Z",
     "start_time": "2022-03-30T11:40:53.948537Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T12:40:43.555968Z",
     "start_time": "2022-03-30T12:40:43.548006Z"
    }
   },
   "outputs": [],
   "source": [
    "# create function to process comments, removing stopwords, punctuation and filters on word type tags\n",
    "# function must take a list of strings (comments) as input\n",
    "# output processed comment and tokenised comment\n",
    "\n",
    "def process_comments(comments):\n",
    "\n",
    "    nlp = textacy.load_spacy_lang('en_core_web_sm')\n",
    "    processed_words = []\n",
    "    tokenised_words = []\n",
    "    \n",
    "    for comment in nlp.pipe(comments, batch_size=200):\n",
    "        tokens = [token \n",
    "                  for token in comment \n",
    "                  if token.is_stop == False\n",
    "                  and token.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "                  and token.pos_ != 'PUNCT']\n",
    "        doc_ = ''\n",
    "        for token in tokens:\n",
    "            doc_ += str(token) + ' '\n",
    "            \n",
    "        doc_ = doc_.strip()\n",
    "        processed_words.append(doc_)\n",
    "        tokenised_words.append(tokens)\n",
    "\n",
    "    return processed_words, tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:10:34.658432Z",
     "start_time": "2022-03-30T14:10:34.620100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['boughtbought value', 'lies challenged right based think'],\n",
       " [[boughtbought, value], [lies, challenged, right, based, think]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "process_comments(df['comment_clean'][10:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T12:51:18.682768Z",
     "start_time": "2022-03-30T12:41:00.404694Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run function on comments\n",
    "\n",
    "processed_comment, tokenised_comment = process_comments(df['comment_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T13:37:12.101840Z",
     "start_time": "2022-03-30T13:37:11.743469Z"
    }
   },
   "outputs": [],
   "source": [
    "# put results into separate columns in dataframe\n",
    "\n",
    "df['processed_comment'] = processed_comment\n",
    "df['tokenised_comment'] = tokenised_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T13:37:40.099415Z",
     "start_time": "2022-03-30T13:37:40.069619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>opinion</th>\n",
       "      <th>price</th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>tokenised_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>hydrogen</td>\n",
       "      <td>RE: Hydro</td>\n",
       "      <td>Yes Sir.</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>yes sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>[sir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>Sycho</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Lets keep your 12:35 post to ourselves and kee...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>lets keep your post ourselves and keep realyou...</td>\n",
       "      <td>lets post realyour knowledge research good kno...</td>\n",
       "      <td>[lets, post, realyour, knowledge, research, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>TomE</td>\n",
       "      <td>GGPSP</td>\n",
       "      <td>So what happened to the \"Expect a sudden jump ...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>what happened the expect sudden jump price its...</td>\n",
       "      <td>happened expect sudden jump price fallen start...</td>\n",
       "      <td>[happened, expect, sudden, jump, price, fallen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      user      title  \\\n",
       "0  7 Dec '21  hydrogen  RE: Hydro   \n",
       "1  7 Dec '21     Sycho      Hydro   \n",
       "2  7 Dec '21      TomE      GGPSP   \n",
       "\n",
       "                                             comment     opinion  price  \\\n",
       "0                                           Yes Sir.  No Opinion  14.05   \n",
       "1  Lets keep your 12:35 post to ourselves and kee...  No Opinion  14.05   \n",
       "2  So what happened to the \"Expect a sudden jump ...  No Opinion  14.05   \n",
       "\n",
       "                                       comment_clean  \\\n",
       "0                                            yes sir   \n",
       "1  lets keep your post ourselves and keep realyou...   \n",
       "2  what happened the expect sudden jump price its...   \n",
       "\n",
       "                                   processed_comment  \\\n",
       "0                                                sir   \n",
       "1  lets post realyour knowledge research good kno...   \n",
       "2  happened expect sudden jump price fallen start...   \n",
       "\n",
       "                                   tokenised_comment  \n",
       "0                                              [sir]  \n",
       "1  [lets, post, realyour, knowledge, research, go...  \n",
       "2  [happened, expect, sudden, jump, price, fallen...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Sentiment Words csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:11:30.862780Z",
     "start_time": "2022-03-30T14:11:30.680400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score\n",
       "0  adj  .22-caliber        0.0        0.0\n",
       "1  adj  .22-calibre        0.0        0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load sentiment words .csv file\n",
    "sen = pd.read_csv('resources/sentiment_words.csv')\n",
    "sen.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:11:35.354827Z",
     "start_time": "2022-03-30T14:11:35.307155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'NOUN', 'ADV', 'VERB'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make pos columns caps to align with textacy libraries\n",
    "sen.pos = sen.pos.map(lambda x: x.upper())\n",
    "sen.pos.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T13:57:20.995295Z",
     "start_time": "2022-03-30T13:57:20.647244Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up a default dictionary\n",
    "sen_dict = defaultdict(dict)\n",
    "\n",
    "# iterate through rows as tuples, populating dictionary with scores as above\n",
    "for row in sen.itertuples():\n",
    "    sen_dict[row.pos][row.word] = {'pos_score': row.pos_score, 'neg_score': row.neg_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:07:57.926176Z",
     "start_time": "2022-03-30T14:07:57.909840Z"
    }
   },
   "outputs": [],
   "source": [
    "# create function to take tokenised comment and derive an average positive and negative sentiment score\n",
    "\n",
    "def scorer(tokens):\n",
    "    \n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        try:\n",
    "            pos_scores.append(sen_dict[token.pos_][token.lemma_]['pos_score'])\n",
    "            neg_scores.append(sen_dict[token.pos_][token.lemma_]['neg_score'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # set default value if no token found\n",
    "    if len(pos_scores) == 0:\n",
    "        pos_scores = [0.]\n",
    "    if len(neg_scores) == 0:\n",
    "        neg_scores = [0.]\n",
    "        \n",
    "    return [np.mean(pos_scores), np.mean(neg_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:08:44.680124Z",
     "start_time": "2022-03-30T14:08:37.599217Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply scorer function to tokenised comment column\n",
    "\n",
    "scores = df['tokenised_comment'].map(scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:09:29.239613Z",
     "start_time": "2022-03-30T14:09:29.139354Z"
    }
   },
   "outputs": [],
   "source": [
    "# populate dataframe columns with average pos and neg scores\n",
    "\n",
    "df['pos_score'] = scores.map(lambda x: x[0])\n",
    "df['neg_score'] = scores.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T16:51:21.598656Z",
     "start_time": "2022-03-30T16:51:21.415809Z"
    }
   },
   "outputs": [],
   "source": [
    "# create positive - negative scores for final sentiment measure\n",
    "\n",
    "df['pos-neg_score'] = df['pos_score'] - df['neg_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T16:52:56.591102Z",
     "start_time": "2022-03-30T16:52:56.468783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>opinion</th>\n",
       "      <th>price</th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>tokenised_comment</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos-neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128114</th>\n",
       "      <td>18 Feb '22</td>\n",
       "      <td>JONNO100</td>\n",
       "      <td>RE: Take comfort</td>\n",
       "      <td>Zoros  A VERY excellent post  ATB Jonno</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>13.750</td>\n",
       "      <td>zoros very excellent post atb jonno</td>\n",
       "      <td>zoros excellent</td>\n",
       "      <td>[zoros, excellent]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11950</th>\n",
       "      <td>7 Oct '21</td>\n",
       "      <td>GoldenI</td>\n",
       "      <td>RE: Nice to see a bit of levity</td>\n",
       "      <td>19, excellent</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>18.150</td>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[excellent]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>9 Sep '21</td>\n",
       "      <td>Lyndon69</td>\n",
       "      <td>Mr burns quote</td>\n",
       "      <td>âââââEXCELLENTââââ</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>18.800</td>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[excellent]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78199</th>\n",
       "      <td>4 Nov '20</td>\n",
       "      <td>Soundman1</td>\n",
       "      <td>RE: Havieron to restore Newcrest's Telfer grea...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>21.375</td>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[excellent]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112759</th>\n",
       "      <td>27 Jun '20</td>\n",
       "      <td>mickey1122</td>\n",
       "      <td>RE: GGPHelp.co.uk FAQ</td>\n",
       "      <td>Excellent BR</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>12.000</td>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[excellent]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123837</th>\n",
       "      <td>19 Mar '22</td>\n",
       "      <td>Aurora1</td>\n",
       "      <td>RE: New To Board</td>\n",
       "      <td>More GGP</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>15.740</td>\n",
       "      <td>more ggp</td>\n",
       "      <td>ggp</td>\n",
       "      <td>[ggp]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71950</th>\n",
       "      <td>1 Dec '20</td>\n",
       "      <td>Stout</td>\n",
       "      <td>RE: GGPSP</td>\n",
       "      <td>MM's hunting for sellers!</td>\n",
       "      <td>Strong Buy</td>\n",
       "      <td>27.250</td>\n",
       "      <td>mms hunting for sellers</td>\n",
       "      <td>mms hunting sellers</td>\n",
       "      <td>[mms, hunting, sellers]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71935</th>\n",
       "      <td>1 Dec '20</td>\n",
       "      <td>seen_it_done_it</td>\n",
       "      <td>RE: A blue finish is quite possible...</td>\n",
       "      <td>Yay!! hooray!!!!</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>27.250</td>\n",
       "      <td>yay hooray</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71929</th>\n",
       "      <td>1 Dec '20</td>\n",
       "      <td>Bancal</td>\n",
       "      <td>RE: Was yesterday’s RNS the first revelation o...</td>\n",
       "      <td>Thanks GGPThruandtru</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>27.500</td>\n",
       "      <td>thanks ggpthruandtru</td>\n",
       "      <td>thanks</td>\n",
       "      <td>[thanks]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>hydrogen</td>\n",
       "      <td>RE: Hydro</td>\n",
       "      <td>Yes Sir.</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.050</td>\n",
       "      <td>yes sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>[sir]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130539 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date             user  \\\n",
       "128114  18 Feb '22         JONNO100   \n",
       "11950    7 Oct '21          GoldenI   \n",
       "16000    9 Sep '21         Lyndon69   \n",
       "78199    4 Nov '20        Soundman1   \n",
       "112759  27 Jun '20       mickey1122   \n",
       "...            ...              ...   \n",
       "123837  19 Mar '22          Aurora1   \n",
       "71950    1 Dec '20            Stout   \n",
       "71935    1 Dec '20  seen_it_done_it   \n",
       "71929    1 Dec '20           Bancal   \n",
       "0        7 Dec '21         hydrogen   \n",
       "\n",
       "                                                    title  \\\n",
       "128114                                   RE: Take comfort   \n",
       "11950                     RE: Nice to see a bit of levity   \n",
       "16000                                      Mr burns quote   \n",
       "78199   RE: Havieron to restore Newcrest's Telfer grea...   \n",
       "112759                              RE: GGPHelp.co.uk FAQ   \n",
       "...                                                   ...   \n",
       "123837                                   RE: New To Board   \n",
       "71950                                           RE: GGPSP   \n",
       "71935              RE: A blue finish is quite possible...   \n",
       "71929   RE: Was yesterday’s RNS the first revelation o...   \n",
       "0                                               RE: Hydro   \n",
       "\n",
       "                                        comment     opinion   price  \\\n",
       "128114  Zoros  A VERY excellent post  ATB Jonno  No Opinion  13.750   \n",
       "11950                             19, excellent  No Opinion  18.150   \n",
       "16000      âââââEXCELLENTââââ  No Opinion  18.800   \n",
       "78199                                 Excellent  No Opinion  21.375   \n",
       "112759                             Excellent BR  No Opinion  12.000   \n",
       "...                                         ...         ...     ...   \n",
       "123837                                 More GGP  No Opinion  15.740   \n",
       "71950                 MM's hunting for sellers!  Strong Buy  27.250   \n",
       "71935                          Yay!! hooray!!!!  No Opinion  27.250   \n",
       "71929                      Thanks GGPThruandtru  No Opinion  27.500   \n",
       "0                                      Yes Sir.  No Opinion  14.050   \n",
       "\n",
       "                              comment_clean    processed_comment  \\\n",
       "128114  zoros very excellent post atb jonno      zoros excellent   \n",
       "11950                             excellent            excellent   \n",
       "16000                             excellent            excellent   \n",
       "78199                             excellent            excellent   \n",
       "112759                            excellent            excellent   \n",
       "...                                     ...                  ...   \n",
       "123837                             more ggp                  ggp   \n",
       "71950               mms hunting for sellers  mms hunting sellers   \n",
       "71935                            yay hooray                        \n",
       "71929                  thanks ggpthruandtru               thanks   \n",
       "0                                   yes sir                  sir   \n",
       "\n",
       "              tokenised_comment  pos_score  neg_score  pos-neg_score  \n",
       "128114       [zoros, excellent]        1.0        0.0            1.0  \n",
       "11950               [excellent]        1.0        0.0            1.0  \n",
       "16000               [excellent]        1.0        0.0            1.0  \n",
       "78199               [excellent]        1.0        0.0            1.0  \n",
       "112759              [excellent]        1.0        0.0            1.0  \n",
       "...                         ...        ...        ...            ...  \n",
       "123837                    [ggp]        0.0        0.0            0.0  \n",
       "71950   [mms, hunting, sellers]        0.0        0.0            0.0  \n",
       "71935                        []        0.0        0.0            0.0  \n",
       "71929                  [thanks]        0.0        0.0            0.0  \n",
       "0                         [sir]        0.0        0.0            0.0  \n",
       "\n",
       "[130539 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('pos_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:21:58.413110Z",
     "start_time": "2022-03-30T14:21:58.332397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zoros very excellent post atb jonno\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent reposte jbgla\n",
      "============================================================\n",
      "\n",
      "here you are none researchers have\n",
      "============================================================\n",
      "\n",
      "this awesome\n",
      "============================================================\n",
      "\n",
      "yes that was awesome\n",
      "============================================================\n",
      "\n",
      "you were lucky bargin well done\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the top 10 comments for positive\n",
    "\n",
    "for comment in df.sort_values('pos_score', ascending=False)['comment_clean'][0:10]:\n",
    "    print(comment)\n",
    "    print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:24:10.777651Z",
     "start_time": "2022-03-30T14:24:10.662021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indeed doggy and could get very messy lol\n",
      "============================================================\n",
      "\n",
      "bads hithanks very much\n",
      "============================================================\n",
      "\n",
      "abusive\n",
      "============================================================\n",
      "\n",
      "unlucky unfortunately\n",
      "============================================================\n",
      "\n",
      "stinks\n",
      "============================================================\n",
      "\n",
      "outrageous\n",
      "============================================================\n",
      "\n",
      "what are you worried about\n",
      "============================================================\n",
      "\n",
      "stinks\n",
      "============================================================\n",
      "\n",
      "the latter but have been chastised for askingsaying this since january\n",
      "============================================================\n",
      "\n",
      "incorrect\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the top 10 comments for negative score\n",
    "\n",
    "for comment in df.sort_values('neg_score', ascending=False)['comment_clean'][0:10]:\n",
    "    print(comment)\n",
    "    print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T16:51:55.483266Z",
     "start_time": "2022-03-30T16:51:54.781122Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excellent\n",
      "============================================================\n",
      "\n",
      "zoros very excellent post atb jonno\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent\n",
      "============================================================\n",
      "\n",
      "excellent reposte jbgla\n",
      "============================================================\n",
      "\n",
      "here you are none researchers have\n",
      "============================================================\n",
      "\n",
      "you lucky lucky bggers\n",
      "============================================================\n",
      "\n",
      "you were lucky bargin well done\n",
      "============================================================\n",
      "\n",
      "your lucky\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the top 10 comments for sentiment score\n",
    "\n",
    "for comment in df.sort_values('pos-neg_score', ascending=False)['comment_clean'][0:10]:\n",
    "    print(comment)\n",
    "    print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Results are skewed by one word comment. Filtering out shorter comments may yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T16:56:20.336470Z",
     "start_time": "2022-03-30T16:56:20.223415Z"
    }
   },
   "outputs": [],
   "source": [
    "# create column of comment length\n",
    "\n",
    "df['comment_length'] = df.tokenised_comment.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T16:57:57.322708Z",
     "start_time": "2022-03-30T16:57:57.148042Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter dataframe by comments of 10 words or more\n",
    "\n",
    "df_filtered = df[df.comment_length > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T17:00:45.970933Z",
     "start_time": "2022-03-30T17:00:45.925972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy buy buy buy buy buy buy buy buy buy buy buy buy goodbye sorters dont cryfor those that dont remember mary hopkins lol atb\n",
      "============================================================\n",
      "\n",
      "many was thinking another hav discovery scally etc would transformational for ggp when all along hav its own think ghs superlative amazing just perfect happy days gla\n",
      "============================================================\n",
      "\n",
      "this has been example good manners good banter and excellent research thanks allmerry christmas all the ggp family and happy prosperous safe and healthy new yearcheers stellabob\n",
      "============================================================\n",
      "\n",
      "are totally agree our assets are the best the business the moment mms are taking the but will come good time\n",
      "============================================================\n",
      "\n",
      "bamps you deserve all the thanks you receive mate excellent poster whos posts always enjoy looking out for\n",
      "============================================================\n",
      "\n",
      "patience koffee will see you holding very good investment indeedfundamentals are course excellent and augurs wellgood luckviking\n",
      "============================================================\n",
      "\n",
      "excellent was the one trying stop her putting more lol wish hadnt told her more cautious now good luck all mums out there\n",
      "============================================================\n",
      "\n",
      "beautiful hydro just beautiful all know how important family reunions are although covid aware another great post this morning\n",
      "============================================================\n",
      "\n",
      "merc most friends this are shrewd and sagacious investors but also enjoy light hearted debate and good humour qualities not enjoyed everyone this debatetig\n",
      "============================================================\n",
      "\n",
      "thanks triggaa fool always finds bigger fool admire him only joking great contributions all the very best\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the top 10 comments for sentiment score in the filtered dataframe\n",
    "\n",
    "for comment in df_filtered.sort_values('pos-neg_score', ascending=False)['comment_clean'][0:10]:\n",
    "    print(comment)\n",
    "    print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T17:00:35.045839Z",
     "start_time": "2022-03-30T17:00:34.983416Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exactly ttb they are clearly nasty gloating individuals who wants like thatwaste space and should just reported for the disruptive gloating attempts\n",
      "============================================================\n",
      "\n",
      "tymers you have lot anger life cant that bad can laughter and light hearted banter cant bad thing\n",
      "============================================================\n",
      "\n",
      "long term shareholder very disappointed you lot these emails are embarrassing and factually incorrect what were you thinking dreadful just dreadful\n",
      "============================================================\n",
      "\n",
      "marky you deal incorrect statements guestimates doom misleading investorstruth something which not associated withhave nice dayviking\n",
      "============================================================\n",
      "\n",
      "banging your head against brick wall unfortunately redirons with the low investor mentality means blame anyone they can its pathetic stupid naive yet understandable degree but inevitable embarrassing unfortunately\n",
      "============================================================\n",
      "\n",
      "tymers need for your abusive post then making excuses and have walk need for another one your abusive replies thankstime log off the grumpies are awakesee tomorrow call that mondayatbtom\n",
      "============================================================\n",
      "\n",
      "sorry pain can someone please provide link ggp telegram having problems reconnecting after inadvertently deleting chat many thanks\n",
      "============================================================\n",
      "\n",
      "south eastjaguar ggphelp greatlandgold thank you for sending tweet well continue suspend accounts that keep reposting abusive disruptive and offtopic content\n",
      "============================================================\n",
      "\n",
      "find this rise the share price deeply distressing continues shall have change username from impecunious pecunious imagine the inconvenience that blame gervaise heddle and callum baxter myself this habit finding gold truly deplorable\n",
      "============================================================\n",
      "\n",
      "floater isnt that what said them that there are platforms that you can buy those shares oni only get harsh with liars but ill admit that the wrong approach now anyway are heading again\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the bottom 10 comments for sentiment score in the filtered dataframe\n",
    "\n",
    "for comment in df_filtered.sort_values('pos-neg_score', ascending=True)['comment_clean'][0:10]:\n",
    "    print(comment)\n",
    "    print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Vader Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T17:05:01.084272Z",
     "start_time": "2022-03-30T17:05:00.980355Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the Vader Sentiment Analyzer\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vader Sentiment Analyzer, developed by the MIT is a self contained sentiment analyser that is \"specifically attuned to sentiments expressed in social media\". The library built in functions will simplify the steps used above by taking a processed bit of text as an input and outputting a negative, neutral, positive and compound score as a dictionary object\n",
    "\n",
    "Reference https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "- The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation).\n",
    "\n",
    "- The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive).\n",
    "\n",
    "The Github readme also gives the following thresholds that could be used for a classification.\n",
    "- positive sentiment: compound score >= 0.05\n",
    "- neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "- negative sentiment: compound score <= -0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T13:25:26.946189Z",
     "start_time": "2022-03-31T13:25:26.932734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Comment:\n",
      "elise yes know what you mean and agree but just ignore them and try not let upset you \n",
      "\n",
      "Processed Comment:\n",
      "elise know mean agree ignore try let upset \n",
      "\n",
      "VADER Polarity Scores:\n",
      "{'neg': 0.405, 'neu': 0.397, 'pos': 0.198, 'compound': -0.3818}\n"
     ]
    }
   ],
   "source": [
    "# taking a random comment from the full dataframe...\n",
    "i = 105428\n",
    "print('Cleaned Comment:')\n",
    "print(df.comment_clean[i], '\\n')\n",
    "print('Processed Comment:')\n",
    "print(df.processed_comment[i], '\\n')\n",
    "\n",
    "# and processing the scores:\n",
    "print('VADER Polarity Scores:')\n",
    "print(vader.polarity_scores(df.processed_comment[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T13:43:32.441592Z",
     "start_time": "2022-03-31T13:43:09.073825Z"
    }
   },
   "outputs": [],
   "source": [
    "# create series for each comments vader score dictionaries\n",
    "\n",
    "vader_scores = df['processed_comment'].map(vader.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T13:55:40.698920Z",
     "start_time": "2022-03-31T13:55:39.918488Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit to dictionary vectorizer\n",
    "dvec = DictVectorizer()\n",
    "\n",
    "vader_scores = dvec.fit_transform(vader_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T14:03:36.833139Z",
     "start_time": "2022-03-31T14:03:36.803673Z"
    }
   },
   "outputs": [],
   "source": [
    "# iterate through dvec features and add to main dataframe\n",
    "\n",
    "for i, col in enumerate(dvec.feature_names_):\n",
    "    df['vader_{}'.format(col)] = vader_scores[:, i].toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T14:26:58.773868Z",
     "start_time": "2022-03-31T14:26:58.716922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>opinion</th>\n",
       "      <th>price</th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>tokenised_comment</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos-neg_score</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>hydrogen</td>\n",
       "      <td>RE: Hydro</td>\n",
       "      <td>Yes Sir.</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>yes sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>[sir]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 Dec '21</td>\n",
       "      <td>Sycho</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>Lets keep your 12:35 post to ourselves and kee...</td>\n",
       "      <td>No Opinion</td>\n",
       "      <td>14.05</td>\n",
       "      <td>lets keep your post ourselves and keep realyou...</td>\n",
       "      <td>lets post realyour knowledge research good kno...</td>\n",
       "      <td>[lets, post, realyour, knowledge, research, go...</td>\n",
       "      <td>0.175012</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.138936</td>\n",
       "      <td>21</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      user      title  \\\n",
       "0  7 Dec '21  hydrogen  RE: Hydro   \n",
       "1  7 Dec '21     Sycho      Hydro   \n",
       "\n",
       "                                             comment     opinion  price  \\\n",
       "0                                           Yes Sir.  No Opinion  14.05   \n",
       "1  Lets keep your 12:35 post to ourselves and kee...  No Opinion  14.05   \n",
       "\n",
       "                                       comment_clean  \\\n",
       "0                                            yes sir   \n",
       "1  lets keep your post ourselves and keep realyou...   \n",
       "\n",
       "                                   processed_comment  \\\n",
       "0                                                sir   \n",
       "1  lets post realyour knowledge research good kno...   \n",
       "\n",
       "                                   tokenised_comment  pos_score  neg_score  \\\n",
       "0                                              [sir]   0.000000   0.000000   \n",
       "1  [lets, post, realyour, knowledge, research, go...   0.175012   0.036076   \n",
       "\n",
       "   pos-neg_score  comment_length  vader_compound  vader_neg  vader_neu  \\\n",
       "0       0.000000               1           0.000      0.000      1.000   \n",
       "1       0.138936              21           0.926      0.067      0.426   \n",
       "\n",
       "   vader_pos  \n",
       "0      0.000  \n",
       "1      0.508  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to csv..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T14:04:53.839154Z",
     "start_time": "2022-03-31T14:04:48.584207Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../../../GA/Capstone/scrapes/sentiment_scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textacy",
   "language": "python",
   "name": "textacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
